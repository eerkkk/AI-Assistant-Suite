import commonApiService from "@/services/api-service/common-api-service";
import { PromptTemplate, type OpenAI } from "langchain";
import { StructuredOutputParser } from "langchain/output_parsers";
import z from "zod";

export interface SummaryParameters {
  textToSummarise: string;
  characterCount: number;
}

class SummariseLLMQueryService {
  generateSummariserParser = () =>
    StructuredOutputParser.fromZodSchema(
      z.object({
        summary: z
          .string()
          .describe("summary text generated by the summariser model"),
      })
    );

  generateSummaryPromptTemplate = () => {
    const parser = this.generateSummariserParser();
    const formatInstructions = parser.getFormatInstructions();

    return new PromptTemplate({
      template: `
    Summarize the following text in your own words. Incorporate the summary of previous text into your summary.
    Keep your summary within {characterCount} characters.

    ## Previous Text Summary

    {previousSummary}

    TLDR

    {textToSummarise}

    {format_instructions}
    `,
      inputVariables: ["textToSummarise", "characterCount", "previousSummary"],
      partialVariables: { format_instructions: formatInstructions },
    });
  };

  getSummaryByChunks = async (
    queryChunks: string[],
    prompt: PromptTemplate,
    characterCount: number,
    model: OpenAI
  ) => {
    const parser = this.generateSummariserParser();
    let summary = "";

    for (const chunk of queryChunks) {
      const inputParams = {
        textToSummarise: chunk,
        characterCount: characterCount / queryChunks.length,
        previousSummary: summary,
      };
      const llmInput = await commonApiService.generateFormattedLLMInput(
        prompt,
        inputParams
      );
      const llmResponse = await model.call(llmInput);
      const response = await parser.parse(llmResponse);
      summary = response.summary;
    }

    return { response: summary };
  };

  generateSummary = async (summaryParameters: SummaryParameters) => {
    const { characterCount, textToSummarise } = summaryParameters;

    const model = commonApiService.generateModel();

    const prompt = this.generateSummaryPromptTemplate();

    const baseInputParams = {
      textToSummarise: ".",
      characterCount: characterCount,
      previousSummary: "",
    };
    const baseLLMInput = await commonApiService.generateFormattedLLMInput(
      prompt,
      baseInputParams
    );

    const queryChunks = await commonApiService.generateQueryChunks(
      model,
      baseLLMInput,
      textToSummarise
    );

    return this.getSummaryByChunks(queryChunks, prompt, characterCount, model);
  };
}

const summariseLLMQueryService = new SummariseLLMQueryService();
export default summariseLLMQueryService;
